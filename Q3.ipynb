{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def homing_nn_TD(n_trials,learning_rate,eps,gamma):\n",
    "\n",
    "    # Solving homing task with on-policy TD (SARSA)\n",
    "\n",
    "    n_steps = 50\n",
    "\n",
    "    ## Definition of the environment\n",
    "    N = 7                               #height of the gridworld ---> number of rows\n",
    "    M = 7                               #length of the gridworld ---> number of columns\n",
    "    N_states = N * M                     #total number of states\n",
    "    states_matrix = np.eye(N_states)\n",
    "    N_actions = 4                                           #number of possible actions in each state: 1->N 2->E 3->S 4->W\n",
    "    action_row_change = np.array([-1,0,+1,0])               #number of cell shifted in vertical as a function of the action\n",
    "    action_col_change = np.array([0,+1,0,-1])               #number of cell shifted in horizontal as a function of the action\n",
    "    End = np.array([1, 1])                                  #terminal state--->reward\n",
    "    s_end = np.ravel_multi_index(End,dims=(N,M),order='F')  #terminal state. Conversion in single index\n",
    "\n",
    "    ## Parameters of the model\n",
    "    #gamma = 0.9                        #discounting factor\n",
    "                                        #high value is better but it cost more time to decrese steps in the begining\n",
    "    #learning_rate = 0.3                #constant step-size parameter (learning rate), high value is better\n",
    "    #eps = 0.5                          #epsilon-greedy SARSA\n",
    "    \n",
    "    ## Rewards\n",
    "    R = 10                              #only when the robot reaches the charger, sited in End state\n",
    "\n",
    "    ## Variables\n",
    "    weights = np.random.rand(N_actions,N_states)  \n",
    "    learning_curve = np.zeros((1,n_trials))\n",
    "\n",
    "    ## SARSA\n",
    "\n",
    "    # Start trials\n",
    "    for trial in range(n_trials):\n",
    "\n",
    "        # Initialization\n",
    "        Start = np.array([np.random.randint(N),np.random.randint(M)])   #random start\n",
    "        s_start = np.ravel_multi_index(Start,dims=(N,M),order='F')      #conversion in single index\n",
    "        state = Start                                                   #set current state\n",
    "        s_index = s_start                                               #conversion in single index\n",
    "        step = 0\n",
    "       \n",
    "        # Start steps\n",
    "        while s_index != s_end and step <= n_steps:\n",
    "\n",
    "            step += 1\n",
    "            learning_curve[0,trial] = step\n",
    "\n",
    "            input_vector = states_matrix[:,s_index].reshape(N_states,1) #convert the state into an input vector 12 by 1\n",
    "\n",
    "            #compute Qvalues. Qvalue=logsig(weights*input). Qvalue is 2x1, one value for each output neuron\n",
    "            Q = 1 / ( 1 + np.exp( - weights.dot(input_vector)))    #Qvalue is 2x1 implementation of logsig(4(N_actions) by 1)\n",
    "\n",
    "            #eps-greedy policy implementation\n",
    "            greedy = (np.random.rand() > eps)               #1--->greedy action 0--->non-greedy action\n",
    "            if greedy:\n",
    "                action = np.argmax(Q)                           #pick best action\n",
    "            else:\n",
    "                action = np.random.randint(N_actions)           #pick random action\n",
    "\n",
    "            state_new = np.array([0,0])\n",
    "            #move into a new state\n",
    "            state_new[0] = state[0] + action_row_change[action]\n",
    "            state_new[1] = state[1] + action_col_change[action]\n",
    "\n",
    "            #put the robot back in grid if it goes out. Consider also the option to give a negative reward\n",
    "            if state_new[0] < 0:\n",
    "                state_new[0] = 0\n",
    "            if state_new[0] >= N:\n",
    "                state_new[0] = N-1\n",
    "            if state_new[1] < 0:\n",
    "                state_new[1] = 0\n",
    "            if state_new[1] >= M:\n",
    "                state_new[1] = M-1\n",
    "\n",
    "            s_index_new = np.ravel_multi_index(state_new,dims=(N,M),order='F')  #conversion in a single index\n",
    "\n",
    "            ## TODO update Qvalues. Only if is not the first step\n",
    "            if step > 1:\n",
    "                # Update weights\n",
    "                dw = learning_rate * (r_old - Q_old + gamma * Q[action]) * output_old.dot(input_old.T)\n",
    "                weights += dw\n",
    "                \n",
    "            #store variables for sarsa computation in the next step\n",
    "            output = np.zeros((N_actions,1))\n",
    "            output[action] = 1\n",
    "            \n",
    "            #update variables\n",
    "            output_old = output\n",
    "            input_old = input_vector\n",
    "            Q_old = Q[action]\n",
    "            r_old = 0\n",
    "   \n",
    "            state[0] = state_new[0]\n",
    "            state[1] = state_new[1]\n",
    "            s_index = s_index_new\n",
    "\n",
    "            ## TODO: check if state is terminal and update the weights consequently\n",
    "            if s_index == s_end:\n",
    "                #pass   #pass means doing nothing\n",
    "                        \n",
    "                # Update weights for the terminal state\n",
    "                dw = learning_rate * (R - Q_old) * output_old.dot(input_old.T)\n",
    "                weights += dw             \n",
    "                \n",
    "                pass\n",
    "    \n",
    "       \n",
    "    return learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########    learning_rate    ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nTrials = 500        # should be integer >0\n",
    "learning_rate = np.linspace(0, 1, 10)\n",
    "eps = 0.1       # should be real, Greater or Equal to 0; epsilon=0 Greedy, otherwise epsilon-Greedy\n",
    "gamma = 0.5         # should be real, positive, smaller than 1\n",
    "repetitions = 50    # number of episodes, should be integer, greater than 0; for statistical reasons\n",
    "\n",
    "N_actions = 4\n",
    "N_states = 49\n",
    "\n",
    "average_steps = np.zeros(10)\n",
    "\n",
    "# Main loop\n",
    "for i in np.arange(learning_rate.size):\n",
    "    \n",
    "    steps = homing_nn_TD(nTrials, learning_rate[i], eps,gamma)\n",
    "    average_steps[i] = np.mean(steps)\n",
    "    print(i)\n",
    "l = average_steps\n",
    "\n",
    "#plt.subplots(1, 1)\n",
    "#plt.plot(learning_rate, average_steps)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(l1, average_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########    eps   ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nTrials = 500        # should be integer >0\n",
    "eps = np.linspace(0, 1, 10)\n",
    "learning_rate = 0.5       # should be real, Greater or Equal to 0; epsilon=0 Greedy, otherwise epsilon-Greedy\n",
    "gamma = 0.5         # should be real, positive, smaller than 1\n",
    "repetitions = 50    # number of episodes, should be integer, greater than 0; for statistical reasons\n",
    "\n",
    "N_actions = 4\n",
    "N_states = 49\n",
    "\n",
    "average_steps = np.zeros(10)\n",
    "\n",
    "# Main loop\n",
    "for i in np.arange(10):\n",
    "    \n",
    "    steps = homing_nn_TD(nTrials, learning_rate, eps[i],gamma)\n",
    "    average_steps[i] = np.mean(steps)\n",
    "    #print(i)\n",
    "e = average_steps\n",
    "\n",
    "#plt.subplots(1, 1)\n",
    "#plt.plot(eps, average_steps)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(e1, average_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########    gamma  ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nTrials = 500        # should be integer >0\n",
    "gamma = np.linspace(0, 1, 10)\n",
    "learning_rate = 0.5       # should be real, Greater or Equal to 0; epsilon=0 Greedy, otherwise epsilon-Greedy\n",
    "eps = 0.5         # should be real, positive, smaller than 1\n",
    "\n",
    "\n",
    "N_actions = 4\n",
    "N_states = 49\n",
    "\n",
    "average_steps = np.zeros(10)\n",
    "\n",
    "# Main loop\n",
    "for i in np.arange(10):\n",
    "    \n",
    "    steps = homing_nn_TD(nTrials,learning_rate, eps, gamma[i])\n",
    "    average_steps[i] = np.mean(steps)\n",
    "    print(i)\n",
    "g = average_steps\n",
    "\n",
    "#plt.subplots(1, 1)\n",
    "#plt.plot(gamma, average_steps)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(e1, average_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x = np.linspace(0, 1,10) \n",
    "y = [ l, e, g ]\n",
    "labels=['Learning rate', 'Epsilon', 'Gamma']\n",
    "colors=['r','g','b']\n",
    "\n",
    "# loop over data, labels and colors\n",
    "for i in range(len(y)):\n",
    "    plt.plot(x,y[i],'-',color=colors[i],label=labels[i])\n",
    "\n",
    "\n",
    "plt.legend(fontsize=18)\n",
    "plt.title('Average steps over parameters ',fontsize=18) \n",
    "plt.xlabel('parameters',fontsize = 18)\n",
    "plt.ylabel('Average steps',fontsize = 18)\n",
    "plt.ylim([0,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##plot average learning curve##\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "n_trials = 500\n",
    "eps = 0.5\n",
    "gamma = 0.5                                                     #curve full down very quickly when applying high gamma \n",
    "learning_rate = 0.5\n",
    "repetitions = 10\n",
    "\n",
    "\n",
    "total = np.zeros((repetitions,n_trials))\n",
    "for i in range(repetitions):\n",
    "    total[i,:] =  homing_nn_TD(n_trials,learning_rate,eps,gamma)\n",
    "\n",
    "means = np.mean(total,axis=0)\n",
    "errors = 2 * np.std(total, axis = 0) / np.sqrt(repetitions)\n",
    "\n",
    " \n",
    "# print ending time caculating time\n",
    "#plot figures\n",
    "#plt.title('Exploration steps over each trial with errorbar',fontsize=16)\n",
    "#plt.xlabel('Trials',fontsize=14)\n",
    "#plt.ylabel('Steps',fontsize=14)\n",
    "#plt.ylim([0,60])\n",
    "#plt.errorbar(np.arange(n_trials),means,errors,color='blue',fmt='-',ecolor='red',elinewidth = 3)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##plot average learning curve##\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "n_trials = 500\n",
    "eps = 0.01\n",
    "gamma = 0.99                                                     #curve full down very quickly when applying high gamma \n",
    "learning_rate = 0.99\n",
    "repetitions = 10\n",
    "\n",
    "total_op = np.zeros((repetitions,n_trials))\n",
    "for i in range(repetitions):\n",
    "    total_op[i,:] =  homing_nn_TD(n_trials,learning_rate,eps,gamma)\n",
    "\n",
    "means_op = np.mean(total_op,axis=0)\n",
    "errors_op = 2 * np.std(total_op, axis = 0) / np.sqrt(repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = fig.add_subplot(111)\n",
    "# add labels\n",
    "ax.errorbar(np.arange(n_trials),means, errors, 0, fmt='-',ecolor='r', elinewidth = 3)\n",
    "ln1=ax.plot(np.arange(n_trials),means,'b',linewidth = 1.5, label='unoptimized')\n",
    "ax.errorbar(np.arange(n_trials),means_op, errors_op,fmt='-',ecolor='g',elinewidth = 3)\n",
    "ln2=ax.plot(np.arange(n_trials),means_op,'y',linewidth = 1.5, label='optimized')\n",
    "\n",
    "ln=ln1+ln2\n",
    "labs=[i.get_label() for i in ln]\n",
    "ax.legend(ln,labs)\n",
    "\n",
    "plt.title('Average steps over each trial with eligibilty trace and without',fontsize=18)\n",
    "plt.xlabel('Trial',fontsize = 16)\n",
    "plt.ylabel('Average Steps',fontsize = 16)\n",
    "plt.ylim([0,60])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
